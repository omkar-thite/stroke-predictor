{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0cb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    " \n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321562c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URI to database\n",
    "gcp_bucket = ''\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:5000\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_bucket_name = \"gcp-mlflow-artifacts\"\n",
    "experiment_name = 'stroke-predictor'\n",
    "gcs_artifact_location = f\"gs://{gcs_bucket_name}/mlartifacts/\"\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    mlflow.create_experiment(name=experiment_name, artifact_location=gcs_artifact_location)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a48fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fe392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map({'Male': 0, 'Female': 1, 'Other': -1})\n",
    "df['ever_married'] = df['ever_married'].map({'Yes': 1, 'No': 0})\n",
    "df['Residence_type'] = df['Residence_type'].map({'Urban': 1, 'Rural': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78656f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null bmi values\n",
    "feature_cols = [col for col in df.columns if col not in ['bmi', 'stroke', 'id']]\n",
    "\n",
    "categorical_cols = ['work_type', 'smoking_status']\n",
    "numerical_cols = [col for col in feature_cols if df[col].dtype in ['float64', 'int64'] and col not in categorical_cols]\n",
    "\n",
    "# Split data into missing and non-missing bmi\n",
    "missing_bmi = df[df['bmi'].isna()]\n",
    "not_missing_bmi = df[~df['bmi'].isna()]\n",
    "\n",
    "# Preprocessing for numeric and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline for imputation\n",
    "bmi_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# Check which columns are missing from not_missing_bmi\n",
    "missing_in_train = [col for col in feature_cols if col not in not_missing_bmi.columns]\n",
    "\n",
    "# Fit on non-missing bmi\n",
    "y_train = not_missing_bmi['bmi']\n",
    "X_train = not_missing_bmi[feature_cols]\n",
    "\n",
    "bmi_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict missing bmi\n",
    "X_missing = missing_bmi[feature_cols]\n",
    "predicted_bmi = bmi_pipe.predict(X_missing)\n",
    "\n",
    "# Fill missing values\n",
    "df.loc[missing_bmi.index, 'bmi'] = pd.Series(predicted_bmi, index=missing_bmi.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c811238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    categorical_cols = ['work_type', 'smoking_status']\n",
    "    numerical_cols = ['bmi', 'age', 'avg_glucose_level']\n",
    "\n",
    "    # Define the column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "            ('num', StandardScaler(), numerical_cols)]\n",
    "    )\n",
    "\n",
    "    # Define the model pipeline\n",
    "    xgb_model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier())\n",
    "    ])\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop('stroke', axis=1)\n",
    "    y = df['stroke']\n",
    "\n",
    "    # Fit the pipeline\n",
    "    xgb_model_pipeline.fit(X, y)\n",
    "\n",
    "    y_pred = xgb_model_pipeline.predict(X)\n",
    "    log_loss_ = log_loss(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    mlflow.log_metric('log_loss', log_loss_)\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    joblib.dump(xgb_model_pipeline, \"../models/model_pipeline.pkl\")\n",
    "\n",
    "    # Log the file as an artifact\n",
    "    mlflow.log_artifact(\"../models/model_pipeline.pkl\")\n",
    "    \n",
    "    run = mlflow.active_run()\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "     # Log the model using MLflow's sklearn flavor\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=xgb_model_pipeline,\n",
    "        name=\"model\"\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    result = mlflow.register_model(model_uri, \"xgb_model\")\n",
    "\n",
    "    # Add a tag to the registered model version\n",
    "    from mlflow.tracking import MlflowClient\n",
    "\n",
    "    client = MlflowClient()\n",
    "    client.set_model_version_tag(\n",
    "        name=\"xgb_model\",\n",
    "        version=result.version,\n",
    "        key=\"stage\",\n",
    "        value=\" development\"  # or \"production\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65671b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "model_uri = f\"runs:/{mlflow.active_run().info.run_id}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c0ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
